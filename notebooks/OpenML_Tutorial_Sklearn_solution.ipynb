{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenML Tutorial Sklearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "wrlV3WHw9hKF",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "# OpenML in Python \n",
        "OpenML is an online collaboration platform for machine learning: \n",
        "\n",
        "* Find or share interesting, well-documented datasets\n",
        "* Define research / modelling goals (tasks)\n",
        "* Explore large amounts of machine learning algorithms, with APIs in Java, R, Python\n",
        "* Log and share reproducible experiments, models, results \n",
        "* Works seamlessly with scikit-learn and other libraries\n",
        "* Large scale benchmarking, compare to state of the art"
      ]
    },
    {
      "metadata": {
        "id": "tGfVXn7q9hKG",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "\n",
        "* `pip install openml`"
      ]
    },
    {
      "metadata": {
        "id": "3QTmbvCn9r87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install openml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AIH74NFkb_z8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Authentication\n",
        "\n",
        "It is important to configure the Python connector with the proper API endpoint (usually good by default) and the proper API key. Find your API key after logging in on OpenML"
      ]
    },
    {
      "metadata": {
        "id": "8TShEX6Zb-sO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import openml\n",
        "\n",
        "openml.config.server = 'https://test.openml.org/api/v1/'\n",
        "openml.config.apikey = 'd488d8afd93b32331cf6ea9d7003d4c3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUI4qW-YdFgL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run model/flow on task\n",
        "\n",
        "Running a scikit-learn model on a task is done using the function `run_model_on_task(...)` ([see docs](https://openml.github.io/openml-python/master/generated/openml.runs.run_model_on_task.html#openml.runs.run_model_on_task)) or `run_flow_on_task(...)`.  In particular, review the `avoid_duplicate_run` option (especially important for tutorials). The function `get_metric_fn` ([doc](https://openml.github.io/openml-python/master/generated/openml.OpenMLRun.html#openml.OpenMLRun)) can be used to obtain metric scores before uploading. \n",
        "* Use the function `run_model_on_task` to run your favorite scikit-learn classifier (e.g., a `Random Forest Classifier`) on the `diabetes` dataset. (Hint: there are several ways of obtaining a task from the diabetes dataset). Report the score.\n",
        "* Use the function `run_flow_on_task` to run another scikit-learn classifier on the `diabetes` dataset. Report the score."
      ]
    },
    {
      "metadata": {
        "id": "5q2zDo3Cftm6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.ensemble\n",
        "\n",
        "task_list = openml.tasks.list_tasks(data_name='diabetes', size=1)\n",
        "task_id = list(task_list.keys())[0]\n",
        "task = openml.tasks.get_task(task_id)\n",
        "clf = sklearn.ensemble.RandomForestClassifier()\n",
        "\n",
        "run = openml.runs.run_model_on_task(clf, task)\n",
        "run = run.publish()\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "print('Uploaded with run id=%d; score=%s' % (run.run_id, scores.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cq-wXtq_hrtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flow = openml.flows.sklearn_to_flow(clf)\n",
        "run = openml.runs.run_flow_on_task(flow, task, avoid_duplicate_runs=False)\n",
        "run = run.publish()\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "print('Uploaded with run id=%d; score=%s' % (run.run_id, scores.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8SZV7kqik3o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Search and Grid Search\n",
        "\n",
        "Scikit-learn natively supports Random Search and Grid Search procedures, to optimize the hyperparameters. These classifiers can natively be used using the openml connector. Read [this article](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html) to understand how these work. \n",
        "\n",
        "* Run Random Search and Grid Search on a SVM from scikit-learn. Make sure to optimize at least 2 hyperparameters. What are the most important hyperparameters? What is the main difference between these two classifiers?"
      ]
    },
    {
      "metadata": {
        "id": "_OC8yLpujTaf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "base = sklearn.svm.SVC()\n",
        "\n",
        "clf = sklearn.model_selection.RandomizedSearchCV(\n",
        "    base, param_distributions=param_dist, n_iter=10\n",
        ")\n",
        "\n",
        "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "print('score=%s' % (scores.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOLdt_UbkxGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "base = sklearn.svm.SVC()\n",
        "\n",
        "clf = sklearn.model_selection.GridSearchCV(\n",
        "    base, param_grid=param_dist\n",
        ")\n",
        "\n",
        "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "print('score=%s' % (scores.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9uO6DapZk5aS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ColumnTransformer and Pipelines\n",
        "\n",
        "Note that we did the previos examples on the `diabetes` dataset. This is a particular nice dataset, as it only contains numeric features and no missing values. In many cases, we have to deal with complicated workflows. For example, the `credit-a` dataset mixes categorical and numeric features, and contains missing values. \n",
        "\n",
        "* verify that our previously used classifier does not work on the `credit-a` dataset. What is the reason for this?\n",
        "* review the following scikit-learn components:\n",
        "  * [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
        "  * [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
        "  * [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
        "  * [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
        "  * [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "  * Remember that in order to make a flow compatible with OpenML, there can be no duplicate polymorph classifiers\n",
        "* create a generat classifier that runs on the `credit-a` (or in general each) dataset. Note that the function `get_features_by_type` from the [OpenMLDataset](https://openml.github.io/openml-python/master/generated/openml.OpenMLDataset.html#openml.OpenMLDataset) object can prove useful."
      ]
    },
    {
      "metadata": {
        "id": "kga1VjnBmxT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task_list = openml.tasks.list_tasks(data_name='credit-a', size=1)\n",
        "task_id = list(task_list.keys())[0]\n",
        "task = openml.tasks.get_task(task_id)\n",
        "clf = sklearn.ensemble.RandomForestClassifier()\n",
        "\n",
        "run = openml.runs.run_model_on_task(clf, task)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yFQcp_GWnNH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing\n",
        "import sklearn.pipeline\n",
        "import sklearn.feature_selection\n",
        "import sklearn.compose\n",
        "import sklearn.impute\n",
        "\n",
        "\n",
        "nominal_indices = task.get_dataset().get_features_by_type('nominal', [task.target_name])\n",
        "numeric_indices = task.get_dataset().get_features_by_type('numeric', [task.target_name])\n",
        "\n",
        "numeric_transformer = sklearn.pipeline.make_pipeline(\n",
        "      sklearn.preprocessing.Imputer(),\n",
        "      sklearn.preprocessing.StandardScaler())\n",
        "\n",
        "# note that the dataset is encoded numerically, hence we can only impute\n",
        "# numeric values, even for the categorical columns. \n",
        "categorical_transformer = sklearn.pipeline.make_pipeline(\n",
        "      sklearn.impute.SimpleImputer(strategy='constant', fill_value=-1),\n",
        "      sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
        "\n",
        "transformer = sklearn.compose.ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('numeric', numeric_transformer, numeric_indices),\n",
        "          ('nominal', categorical_transformer, nominal_indices)],\n",
        "      remainder='passthrough')\n",
        "\n",
        "clf = sklearn.pipeline.make_pipeline(transformer,\n",
        "                                     sklearn.feature_selection.VarianceThreshold(),\n",
        "                                     sklearn.ensemble.RandomForestClassifier())\n",
        "\n",
        "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "print('score=%s' % (scores.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjW29i2_oqjJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pipelines, Columntransformers and Random Search\n",
        "\n",
        "Combine Pipelines, ColumnTransformers and RandomSearchCV to work on any dataset (in particular the `credit-a` dataset). Note that the parameter distribution parameter needs to be adjusted. "
      ]
    },
    {
      "metadata": {
        "id": "PcIzLY_EpBSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing\n",
        "import sklearn.pipeline\n",
        "import sklearn.feature_selection\n",
        "import sklearn.compose\n",
        "import sklearn.impute\n",
        "\n",
        "\n",
        "nominal_indices = task.get_dataset().get_features_by_type('nominal', [task.target_name])\n",
        "numeric_indices = task.get_dataset().get_features_by_type('numeric', [task.target_name])\n",
        "\n",
        "numeric_transformer = sklearn.pipeline.make_pipeline(\n",
        "      sklearn.preprocessing.Imputer(),\n",
        "      sklearn.preprocessing.StandardScaler())\n",
        "\n",
        "# note that the dataset is encoded numerically, hence we can only impute\n",
        "# numeric values, even for the categorical columns. \n",
        "categorical_transformer = sklearn.pipeline.make_pipeline(\n",
        "      sklearn.impute.SimpleImputer(strategy='constant', fill_value=-1),\n",
        "      sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
        "\n",
        "transformer = sklearn.compose.ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('numeric', numeric_transformer, numeric_indices),\n",
        "          ('nominal', categorical_transformer, nominal_indices)],\n",
        "      remainder='passthrough')\n",
        "\n",
        "\n",
        "param_dist = {\n",
        "    'svc__C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    'svc__gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "base = sklearn.svm.SVC()\n",
        "\n",
        "clf = sklearn.pipeline.make_pipeline(transformer,\n",
        "                                     sklearn.feature_selection.VarianceThreshold(),\n",
        "                                     base)\n",
        "\n",
        "search = sklearn.model_selection.RandomizedSearchCV(\n",
        "    clf, param_distributions=param_dist, n_iter=10\n",
        ")\n",
        "\n",
        "run = openml.runs.run_model_on_task(search, task, avoid_duplicate_runs=False)\n",
        "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
        "run = run.publish()\n",
        "\n",
        "print(run.run_id)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}