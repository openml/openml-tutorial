{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrlV3WHw9hKF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenML in Python \n",
    "OpenML is an online collaboration platform for machine learning: \n",
    "\n",
    "* Find or share interesting, well-documented datasets\n",
    "* Define research / modelling goals (tasks)\n",
    "* Explore large amounts of machine learning algorithms, with APIs in Java, R, Python\n",
    "* Log and share reproducible experiments, models, results \n",
    "* Works seamlessly with scikit-learn and other libraries\n",
    "* Large scale benchmarking, compare to state of the art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGfVXn7q9hKG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Installation\n",
    "\n",
    "* `pip install openml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QTmbvCn9r87"
   },
   "outputs": [],
   "source": [
    "!pip install openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIH74NFkb_z8"
   },
   "source": [
    "# Authentication\n",
    "\n",
    "It is important to configure the Python connector with the proper API endpoint (usually good by default) and the proper API key. Find your API key after logging in on OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TShEX6Zb-sO"
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "openml.config.server = 'https://test.openml.org/api/v1/'\n",
    "openml.config.apikey = 'FILL_IN'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUI4qW-YdFgL"
   },
   "source": [
    "# Run model/flow on task\n",
    "\n",
    "Running a scikit-learn model on a task is done using the function `run_model_on_task(...)` ([see docs](https://openml.github.io/openml-python/master/generated/openml.runs.run_model_on_task.html#openml.runs.run_model_on_task)) or `run_flow_on_task(...)`.  In particular, review the `avoid_duplicate_run` option (especially important for tutorials). The function `get_metric_fn` ([doc](https://openml.github.io/openml-python/master/generated/openml.OpenMLRun.html#openml.OpenMLRun)) can be used to obtain metric scores before uploading. \n",
    "* Use the function `run_model_on_task` to run your favorite scikit-learn classifier (e.g., a `Random Forest Classifier`) on the `diabetes` dataset. (Hint: there are several ways of obtaining a task from the diabetes dataset). Report the score.\n",
    "* Use the function `run_flow_on_task` to run another scikit-learn classifier on the `diabetes` dataset. Report the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q2zDo3Cftm6"
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "task_list = openml.tasks.list_tasks(data_name='diabetes', size=1)\n",
    "task_id = list(task_list.keys())[0]\n",
    "task = openml.tasks.get_task(task_id)\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "run = openml.runs.run_model_on_task(clf, task)\n",
    "run = run.publish()\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "print('Uploaded with run id=%d; score=%s' % (run.run_id, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq-wXtq_hrtQ"
   },
   "outputs": [],
   "source": [
    "flow = openml.flows.sklearn_to_flow(clf)\n",
    "run = openml.runs.run_flow_on_task(flow, task, avoid_duplicate_runs=False)\n",
    "run = run.publish()\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "print('Uploaded with run id=%d; score=%s' % (run.run_id, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8SZV7kqik3o"
   },
   "source": [
    "# Random Search and Grid Search\n",
    "\n",
    "Scikit-learn natively supports Random Search and Grid Search procedures, to optimize the hyperparameters. These classifiers can natively be used using the openml connector. Read [this article](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html) to understand how these work. \n",
    "\n",
    "* Run Random Search and Grid Search on a SVM from scikit-learn. Make sure to optimize at least 2 hyperparameters. What are the most important hyperparameters? What is the main difference between these two classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OC8yLpujTaf"
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "base = sklearn.svm.SVC()\n",
    "\n",
    "clf = sklearn.model_selection.RandomizedSearchCV(\n",
    "    base, param_distributions=param_dist, n_iter=10\n",
    ")\n",
    "\n",
    "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "print('score=%s' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOLdt_UbkxGk"
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "base = sklearn.svm.SVC()\n",
    "\n",
    "clf = sklearn.model_selection.GridSearchCV(\n",
    "    base, param_grid=param_dist\n",
    ")\n",
    "\n",
    "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "print('score=%s' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uO6DapZk5aS"
   },
   "source": [
    "# ColumnTransformer and Pipelines\n",
    "\n",
    "Note that we did the previos examples on the `diabetes` dataset. This is a particular nice dataset, as it only contains numeric features and no missing values. In many cases, we have to deal with complicated workflows. For example, the `credit-a` dataset mixes categorical and numeric features, and contains missing values. \n",
    "\n",
    "* verify that our previously used classifier does not work on the `credit-a` dataset. What is the reason for this?\n",
    "* review the following scikit-learn components:\n",
    "  * [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "  * [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "  * [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "  * [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "  * [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "  * Remember that in order to make a flow compatible with OpenML, there can be no duplicate polymorph classifiers\n",
    "* create a generat classifier that runs on the `credit-a` (or in general each) dataset. Note that the function `get_features_by_type` from the [OpenMLDataset](https://openml.github.io/openml-python/master/generated/openml.OpenMLDataset.html#openml.OpenMLDataset) object can prove useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kga1VjnBmxT1"
   },
   "outputs": [],
   "source": [
    "task_list = openml.tasks.list_tasks(data_name='credit-a', size=1)\n",
    "task_id = list(task_list.keys())[0]\n",
    "task = openml.tasks.get_task(task_id)\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "try:\n",
    "  run = openml.runs.run_model_on_task(clf, task)\n",
    "  # Note that this is supposed to throw an error\n",
    "except ValueError as e:\n",
    "  print('Found error: %s' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFQcp_GWnNH-"
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.feature_selection\n",
    "import sklearn.compose\n",
    "import sklearn.impute\n",
    "\n",
    "\n",
    "nominal_indices = task.get_dataset().get_features_by_type('nominal', [task.target_name])\n",
    "numeric_indices = task.get_dataset().get_features_by_type('numeric', [task.target_name])\n",
    "\n",
    "numeric_transformer = sklearn.pipeline.make_pipeline(\n",
    "      sklearn.preprocessing.Imputer(),\n",
    "      sklearn.preprocessing.StandardScaler())\n",
    "\n",
    "# note that the dataset is encoded numerically, hence we can only impute\n",
    "# numeric values, even for the categorical columns. \n",
    "categorical_transformer = sklearn.pipeline.make_pipeline(\n",
    "      sklearn.impute.SimpleImputer(strategy='constant', fill_value=-1),\n",
    "      sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "transformer = sklearn.compose.ColumnTransformer(\n",
    "      transformers=[\n",
    "          ('numeric', numeric_transformer, numeric_indices),\n",
    "          ('nominal', categorical_transformer, nominal_indices)],\n",
    "      remainder='passthrough')\n",
    "\n",
    "clf = sklearn.pipeline.make_pipeline(transformer,\n",
    "                                     sklearn.feature_selection.VarianceThreshold(),\n",
    "                                     sklearn.ensemble.RandomForestClassifier())\n",
    "\n",
    "run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "print('score=%s' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjW29i2_oqjJ"
   },
   "source": [
    "# Pipelines, Columntransformers and Random Search\n",
    "\n",
    "Combine Pipelines, ColumnTransformers and RandomSearchCV to work on any dataset (in particular the `credit-a` dataset). Note that the parameter distribution parameter needs to be adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcIzLY_EpBSv"
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.feature_selection\n",
    "import sklearn.compose\n",
    "import sklearn.impute\n",
    "\n",
    "\n",
    "nominal_indices = task.get_dataset().get_features_by_type('nominal', [task.target_name])\n",
    "numeric_indices = task.get_dataset().get_features_by_type('numeric', [task.target_name])\n",
    "\n",
    "numeric_transformer = sklearn.pipeline.make_pipeline(\n",
    "      sklearn.preprocessing.Imputer(),\n",
    "      sklearn.preprocessing.StandardScaler())\n",
    "\n",
    "# note that the dataset is encoded numerically, hence we can only impute\n",
    "# numeric values, even for the categorical columns. \n",
    "categorical_transformer = sklearn.pipeline.make_pipeline(\n",
    "      sklearn.impute.SimpleImputer(strategy='constant', fill_value=-1),\n",
    "      sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "transformer = sklearn.compose.ColumnTransformer(\n",
    "      transformers=[\n",
    "          ('numeric', numeric_transformer, numeric_indices),\n",
    "          ('nominal', categorical_transformer, nominal_indices)],\n",
    "      remainder='passthrough')\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'svc__C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'svc__gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "base = sklearn.svm.SVC()\n",
    "\n",
    "clf = sklearn.pipeline.make_pipeline(transformer,\n",
    "                                     sklearn.feature_selection.VarianceThreshold(),\n",
    "                                     base)\n",
    "\n",
    "search = sklearn.model_selection.RandomizedSearchCV(\n",
    "    clf, param_distributions=param_dist, n_iter=10\n",
    ")\n",
    "\n",
    "run = openml.runs.run_model_on_task(search, task, avoid_duplicate_runs=False)\n",
    "scores = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "run = run.publish()\n",
    "\n",
    "print(run.run_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OpenML Tutorial Sklearn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
