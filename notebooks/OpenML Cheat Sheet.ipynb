{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "365ab75b-fb74-4fc0-9efb-ea51b2c208e6"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenML Cheat Sheet (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "from openml import datasets, tasks, runs, flows, config, evaluations, study, extensions\n",
    "import os, pandas, sklearn, arff, pprint, numpy, seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hide_input": true,
    "nbpresent": {
     "id": "22990c96-6359-4864-bfc4-eb4c3c5a1ec1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## config\n",
    "\n",
    "Find your API key (required for uploads):\n",
    "* `www.openml.org` > Your profile > API Authentication\n",
    "\n",
    "Main OpenML servers:\n",
    "* Public: `https://www.openml.org/api/v1` (default)\n",
    "* Test: `https://test.openml.org/api/v1` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Set server, API key and cache directory (default: `~/.openml/cache`)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "config.apikey = 'qxlfpbe...ebairtd'\n",
    "config.server = 'https://...'\n",
    "config.set_cache_directory(os.path.expanduser('~/mycache'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Or, create a config file called `~/.openml/config`\n",
    "and add these lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "server=https://www.openml.org/api/v1\n",
    "apikey=qxlfpbeaudtprb23985hcqlfoebairtd\n",
    "cachedir=/homedir/.openml/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "e4f0afda-8f78-4162-b196-b12399a65a5a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## datasets  \n",
    "**`list_datasets(offset=None, size=None, tag=None)`**\n",
    "* `offset` and `size` for paging results\n",
    "* `tag` to filter datasets (e.g. 'uci')\n",
    "* `status`: active, in_preparation, deactivated\n",
    "* `data_name`, `data_version`, `number_instances`,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "1f22460f-b6da-4e90-9437-336b84527224"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dlist = datasets.list_datasets(size=100)\n",
    "pandas.DataFrame.from_dict(dlist, orient='index')[\n",
    "['name','NumberOfInstances', 'NumberOfFeatures']][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`get_dataset(dataset_id)`**\n",
    "* returns **OpenMLDataset** object\n",
    "* automatically downloads and caches the data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "d377efff-2484-4ac3-8706-6434644949fd"
    }
   },
   "outputs": [],
   "source": [
    "odata = datasets.get_dataset(1471)\n",
    "print(odata.name, \"Target: \"+ odata.default_target_attribute, \n",
    "      odata.description[260:308], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`OpenMLDataset`**  \n",
    "\n",
    "**`.features`**: list of features and their properties  \n",
    "**`.qualities`**: list of all dataset properties  \n",
    "**`.get_data`**(target,return_attribute_names=False,return_categorical_indicator=False):  \n",
    "  returns data as numpy arrays, attribute names, and which are categorical  \n",
    "**`.retrieve_class_labels(target_name='class')`**: return all class labels for the given target attribute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data, targets, categorical, attribute_names = odata.get_data(\n",
    "    target=odata.default_target_attribute\n",
    ")\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "eeb5fce8-4073-40c3-ab2b-a211bc77b1d4"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Upload new datasets**\n",
    "* Create a new OpenML dataset with all relevant information\n",
    "* `datasets.functions.create_dataset` for uploading pandas dataframes or numpy arrays\n",
    "* Call **`.publish()`** to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "md = datasets.OpenMLDataset(data_file='dataset.arff', name='t',\n",
    "    description='t', version='1', format='ARFF', licence='CC0',\n",
    "    visibility='public', default_target_attribute='class')\n",
    "data_id = md.publish()\n",
    "\n",
    "print(\"New dataset ID: \" + str(data_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "nbpresent": {
     "id": "ba1405dc-32b8-4518-9904-c54b0cae6757"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## tasks  \n",
    "**`list_tasks(task_type_id=None, offset=None, size=None, ...)`**\n",
    "* `offset` and `size` for paging results, `tag` to filter tags\n",
    "* `task_type_id`: 1=Classification, 2=Regression,...\n",
    "* Dataset properties: `data_tag`, `status`, `data_id`, `data_name`, `number_instances`, `number_features`, `number_classes`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "tlist = tasks.list_tasks(task_type_id=1, size=100)\n",
    "pandas.DataFrame.from_dict(tlist, orient='index')[\n",
    "['name','estimation_procedure']][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`get_task(task_id)`**\n",
    "* returns **OpenMLTask** object\n",
    "    *  includes estimation procedure, target name, cost matrix,...\n",
    "* automatically caches the task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hide_input": false,
    "nbpresent": {
     "id": "8d954b88-96dc-48d5-ad06-524d040a0324"
    }
   },
   "outputs": [],
   "source": [
    "task = tasks.get_task(14951)\n",
    "pprint.pprint(task.estimation_procedure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`OpenMLTask`**  \n",
    "**`.get_dataset()`**: downloads associated dataset   \n",
    "**`.download_split()`**: downloads train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Create new tasks**  \n",
    "...  \n",
    "`Under development`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## flows  \n",
    "**`list_flows(offset=None, size=None, tag=None, uploader=None)`**\n",
    "* returns ID -> flow dict mapping\n",
    "* `offset` and `size` for paging results, `tag` to filter tags\n",
    "* `uploader`: list of uploader IDs to filter on, e.g. [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "flist = flows.list_flows(size=200)\n",
    "pandas.DataFrame.from_dict(flist, orient='index')[\n",
    "    ['name','version','external_version']][100:102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`sklearn_to_flow(sklearn_estimator)`**\n",
    "\n",
    "* converts a scikit-learn estimator or pipeline to an OpenML Flow\n",
    "\n",
    "**`publish()`**\n",
    "\n",
    "* Uploads the flow to the server. Returns ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(data.values[:,0:-1], data.values[:,-1])\n",
    "extension = extensions.get_extension_by_model(lr)\n",
    "flow = extension.model_to_flow(lr)\n",
    "\n",
    "pipe = sklearn.pipeline.Pipeline(steps=[\n",
    "    ('Imputer', sklearn.preprocessing.Normalizer()),\n",
    "    ('Classifier', sklearn.linear_model.LinearRegression())])\n",
    "flow2 = extension.model_to_flow(pipe)\n",
    "# flows.publish(flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## runs  \n",
    "**`list_runs(offset=None, size=None, tag=None, id=None, task=None, flow=None, uploader=None, display_errors=False)`**\n",
    "* `offset` and `size` for paging results, `tag` to filter tags\n",
    "* `id`, `task`, `flow`, `uploader`: list of IDs to filter, e.g. [1,2,3]\n",
    "* `display_errors`: whether to return failed runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "rl = runs.list_runs(task=[14951],size=100)\n",
    "pandas.DataFrame.from_dict(rl, orient='index')[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`get_run(run_id)`**\n",
    "* returns **OpenMLRun** object\n",
    "    *  includes the exact task, exact flow, and all evaluations\n",
    "* automatically caches the run description\n",
    "\n",
    "**OpenMLRun**  \n",
    "**.uploader_name**: full name of the run author  \n",
    "**.flow_name**: full name of the flow  \n",
    "**.parameter_settings**: hyperparameters of the flow  \n",
    "**.evaluations**: key-value pairs of metric and score  \n",
    "**.fold_evaluations**: dict of per-fold evaluations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "rlist = runs.list_runs(task=[14951],size=50)\n",
    "scores = []\n",
    "for id, _ in rlist.items():\n",
    "    run = runs.get_run(id)\n",
    "    scores.append({\"flow\":run.flow_name, \n",
    "                   \"score\":run.evaluations['area_under_roc_curve']})\n",
    "pandas.DataFrame.from_dict(scores)[17:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**`run_flow_on_task(flow, task)`**  \n",
    "**`run_model_on_task(model, task)`**\n",
    "\n",
    "* Runs a flow or model (e.g. sklearn model) on the task\n",
    "* Returns a **OpenMLRun** with all information\n",
    "* Trains and tests the flow of all train/test splits defined by the task\n",
    "\n",
    "**`publish()`**\n",
    "* Publishes the run on OpenML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "task = tasks.get_task(14951)\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "run = runs.run_model_on_task(clf, task)\n",
    "score = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "myrun = run.publish()\n",
    "\n",
    "print(myrun)\n",
    "print(\"Accuracy: {:.2f}%\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## evaluations  \n",
    "**`list_evaluations(function=None, offset=None, size=None, tag=None, id=None, task=None, flow=None, uploader=None, display_errors=False)`**\n",
    "* `function`: evaluation measure, e.g. `area_under_roc_curve'\n",
    "* `offset` and `size` for paging results, `tag` to filter tags\n",
    "* `id`, `task`, `flow`, `uploader`: list of IDs to filter, e.g. [1,2,3]\n",
    "* `per_fold`: if True, returns per-fold evaluations \n",
    "* `setup`: list of hyperparameter setup ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "evals = evaluations.list_evaluations(task=[167133], \n",
    "    function='area_under_roc_curve', size=100)\n",
    "scores = [{\"flow\":e.flow_name[0:70], \"score\":e.value} \n",
    "          for id, e in evals.items()]\n",
    "seaborn.violinplot(x=\"score\", y=\"flow\", cut=0, scale=\"width\", \n",
    "                   data=pandas.DataFrame(scores));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Benchmark suites\n",
    "* Curated collections of tasks for benchmarking\n",
    "* Run any model or pipeline on all tasks\n",
    "* Frictionless evaluation and sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "benchmark_suite = study.get_study('OpenML100')\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "for task_id in benchmark_suite.tasks[0:2]: # take small subset\n",
    "    run = runs.run_model_on_task(clf, tasks.get_task(task_id))\n",
    "    score = run.get_metric_fn(sklearn.metrics.accuracy_score)\n",
    "    print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))\n",
    "    # run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats, display, HTML\n",
    "HTML('''<style>.prompt {display:none;}\n",
    "        .output_subarea pre{width:130%}\n",
    "        </style>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.server = 'https://www.openml.org/api/v1'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
